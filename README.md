# About Resource Allocation
1. **Adaptive federated learning in resource constrained edge computing systems.**  *Wang, Shiqiang and Tuor, Tiffany and Salonidis, Theodoros and Leung, Kin K and Makaya, Christian and He, Ting and Chan, Kevin* IEEE Journal on Selected Areas in Communications 2019 [p1](https://ieeexplore.ieee.org/document/8664630?denied=).  
code & data [adaptive-federated-learning](https://github.com/IBM/adaptive-federated-learning)
2. **Fair Resource Allocation in Federated Learning.**  	*Tian Li, Maziar Sanjabi, Ahmad Beirami, Virginia Smith. ICLR 2020.* [p2](https://arxiv.org/abs/1905.10497)  
 code & data [fair_flearn](https://github.com/litian96/fair_flearn)

# About Security and Privacy
## Backdoor Attacks
1. **How To Backdoor Federated Learning.**  Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, Vitaly Shmatikov Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics  (AISTATS), PMLR 108:2938-2948, 2020. [p1](https://proceedings.mlr.press/v108/bagdasaryan20a.html).
2.  **DBA: Distributed Backdoor Attacks against Federated Learning.** Xie, Chulin and Huang, Keli and Chen, Pin-Yu and Li, Bo, ICLR 2020 [p2](https://openreview.net/pdf?id=rkgyS0VFvr).
3.  **3DFed: Adaptive and Extensible Framework for Covert Backdoor Attack in Federated Learning.** Li, Haoyang and Ye, Qingqing and Hu, Haibo and Li, Jin and Wang, Leixia and Fang, Chengfang and Shi, Jie, 2023 IEEE Symposium on Security and Privacy (SP) [p3](https://ieeexplore.ieee.org/document/10179401)
4.  **IBA: Towards Irreversible Backdoor Attacks in Federated Learning.**, Thuy Dung Nguyen, Tuan A. Nguyen, Anh Tran, Khoa D Doan, Kok-Seng Wong,  Advances in Neural Information Processing Systems 36 (NeurIPS 2023) [p4](https://proceedings.neurips.cc/paper_files/paper/2023/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html), [codes](https://github.com/sail-research/iba)
5.  **Attack of the Tails: Yes, You Really Can Backdoor Federated Learning.**, Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn, Kangwook Lee, Dimitris Papailiopoulos, 34th Conference on Neural Information Processing Systems (NeurIPS 2020) [p5](https://proceedings.neurips.cc/paper_files/paper/2020/hash/b8ffa41d4e492f0fad2f13e29e1762eb-Abstract.html), [codes](https://github.com/ksreenivasan/OOD_Federated_Learning)
6.  **A3FL: adversarially adaptive backdoor attacks to federated learning.**, Hangfan Zhang, Jinyuan Jia, Jinghui Chen, Lu Lin, Dinghao Wu, NeurIPS 2023, [p6](https://openreview.net/forum?id=S6ajVZy6FA), [codes](https://github.com/hfzhang31/A3FL)


## Backdoor Defenses
1. **DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection.** Phillip Rieger, Thien Duc Nguyen, Markus Miettinen, Ahmad-Reza Sadeghi, NDSS 2022 [p1](https://arxiv.org/abs/2201.00763).
2. **Mitigating Distributed Backdoor Attack in Federated Learning Through Mode Connectivity.**, Walter, Kane and Mohammady, Meisam and Nepal, Surya and Kanhere, Salil S, ASIA CCS '24 [p2](https://dl.acm.org/doi/abs/10.1145/3634737.3637682?casa_token=3t1M1TpHN3YAAAAA:lDAw0-qF_zMsBDt8ST3bXe83QxAvlNoUE3MBB8S_6zePpWWF3drhshkszGCOQT06rB0uu9TVVXic).


## Privacy Attacks
1. **Federated Learning Vulnerabilities: Privacy Attacks with Denoising Diffusion Probabilistic Models.**, Gu, Hongyan and Zhang, Xinyi and Li, Jiang and Wei, Hui and Li, Baiqi and Huang, Xinli, WWW '24 [p1](https://dl.acm.org/doi/10.1145/3589334.3645514)

## Privacy Defenses
1. **Concealing Sensitive Samples against Gradient Leakage in Federated Learning.**, Jing Wu, Munawar Hayat, Mingyi Zhou, Mehrtash Harandi, [p1](https://ojs.aaai.org/index.php/AAAI/article/view/30171/32078) [codes](https://github.com/JingWu321/DCS-2)
